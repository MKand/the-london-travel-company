import requests # For making HTTP calls to Gemini API
import json
import os
import psycopg2 # For connecting to PostgreSQL
from pgvector.psycopg2 import register_vector # To easily handle vector types with pgvector library
import time # For rate limiting, if needed
from google import genai
from google.genai.types import EmbedContentConfig

# --- IMPORTANT: PostgreSQL Connection Details ---
# These are details for your local PostgreSQL database.
# You will typically run this in a Docker container (instructions below).
DB_HOST = os.environ.get('PG_HOST', 'localhost')
DB_PORT = os.environ.get('PG_PORT', '5432')
DB_NAME = os.environ.get('PG_DB_NAME', 'london-db')
DB_USER = os.environ.get('PG_USER', 'main')
DB_PASSWORD = os.environ.get('PG_PASSWORD', 'main')

# get root dir of worksapce
# Determine the base directory of the script
base_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(base_dir) # This should be data_london directory
super_parent_dir = os.path.dirname(parent_dir) # This should be data_london directory

os.environ["GOOGLE_APPLICATION_CREDENTIALS"]=os.path.join(super_parent_dir, '.key.json')
os.environ["GOOGLE_CLOUD_PROJECT"] = "o11y-movie-guru"
os.environ["GOOGLE_CLOUD_LOCATION"] = "us-central1"
os.environ["GOOGLE_GENAI_USE_VERTEXAI"] = "TRUE"

# --- Gemini API Key Setup ---
# 1. Go to Google Cloud Console (https://console.cloud.google.com/) or Google AI Studio (https://aistudio.google.com/app/apikey).
# 2. Create or select a project.
# 3. Go to "APIs & Services" -> "Credentials".
# 4. Create an API Key (if you don't have one). Ensure the Gemini API is enabled for your project.
# 5. Replace 'YOUR_GEMINI_API_KEY' with your actual Gemini API key.
#    Alternatively, set it as an environment variable and use `os.environ.get('GEMINI_API_KEY')`.
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY', 'YOUR_GEMINI_API_KEY') # <-- UPDATE THIS KEY

# --- Embedding Model Details ---
# text-embedding-004 typically produces 768-dimensional embeddings.
EMBEDDING_MODEL_NAME = "text-embedding-005"
EMBEDDING_DIMENSION = 768 # Dimension of the embeddings generated by text-embedding-005

# --- Database Connection Initialization ---conn = None
try:
    conn = psycopg2.connect(
        host=DB_HOST,
        port=DB_PORT,
        database=DB_NAME,
        user=DB_USER,
        password=DB_PASSWORD
    )
    register_vector(conn) # Register the vector type for psycopg2
    print("PostgreSQL database connected successfully!")

    # Cursor to execute SQL commands
    cur = conn.cursor()

    # Enable the pgvector extension if not already enabled
    cur.execute("CREATE EXTENSION IF NOT EXISTS vector;")
    conn.commit()
    print("pgvector extension ensured to be enabled.")

except Exception as e:
    print(f"Error connecting to PostgreSQL database or enabling pgvector: {e}")
    print("Please ensure your PostgreSQL server is running and the 'pgvector' extension is installed.")
    print("Refer to the Docker instructions below to set up PostgreSQL with pgvector.")
    exit() # Exit if database connection fails

# --- Gemini API Embedding Function ---
def generate_embedding(text):
    """
    Generates a vector embedding for the given text using the Gemini API.
    """
    try:
       client = genai.Client()
       response = client.models.embed_content(
       model=EMBEDDING_MODEL_NAME,
       contents=text,)
       return response.embeddings[0].values
        
    except requests.exceptions.RequestException as e:
        print(f"Error generating embedding for text '{text}': {e}")
        return None
    except json.JSONDecodeError as e:
        print(f"Error decoding JSON response for text '{text}': {e}")
        return None

# --- Table Creation Functions ---
def create_locations_table():
    """Creates the 'locations' table (for general attractions/sights) if it doesn't exist."""
    cur.execute(f"""
        CREATE TABLE IF NOT EXISTS locations (
            sight_id VARCHAR(50) PRIMARY KEY,
            name VARCHAR(255) NOT NULL,
            category VARCHAR(100),
            description TEXT,
            embedding VECTOR({EMBEDDING_DIMENSION})
        );
    """)
    conn.commit()
    print("Table 'locations' ensured to be created.")

def create_activities_table():
    """Creates the 'activities' table if it doesn't exist."""
    cur.execute(f"""
        CREATE TABLE IF NOT EXISTS activities (
            activity_id VARCHAR(50) PRIMARY KEY,
            name VARCHAR(255) NOT NULL,
            duration_min INT,
            duration_max INT,
            kid_friendliness_score INT,
            cost INT,
            sight_id VARCHAR(50) REFERENCES locations(sight_id), -- Foreign key to locations table
            description TEXT,
            embedding VECTOR({EMBEDDING_DIMENSION})
        );
    """)
    conn.commit()
    print("Table 'activities' ensured to be created.")

# --- Main Data Insertion Logic ---
def insert_locations_data(locations_data_list):
    """Inserts location data with generated embeddings into the 'locations' table."""
    added_count = 0
    print(f"\n--- Adding data to 'locations' table ---")
    for i, item in enumerate(locations_data_list):
        item_name = item['name']
        item_description = item['description']

        print(f"[{i+1}/{len(locations_data_list)}] Generating embedding for location '{item_name}'...")
        embedding_values = generate_embedding(f"item_description: {item_description}, item_name: {item_name}")

        if embedding_values:
            try:
                # Ensure embedding has the correct dimension
                if len(embedding_values) != EMBEDDING_DIMENSION:
                    print(f"Warning: Embedding for location '{item_name}' has dimension {len(embedding_values)}, expected {EMBEDDING_DIMENSION}. Skipping.")
                    continue

                cur.execute("""
                    INSERT INTO locations (sight_id, name, category, description, embedding)
                    VALUES (%s, %s, %s, %s, %s)
                    ON CONFLICT (sight_id) DO UPDATE SET
                        name = EXCLUDED.name,
                        category = EXCLUDED.category,
                        description = EXCLUDED.description,
                        embedding = EXCLUDED.embedding;
                """, (
                    item['sight_id'],
                    item_name,
                    item['category'],
                    item_description,
                    embedding_values # psycopg2 with register_vector handles this list directly
                ))
                conn.commit()
                print(f"Added/Updated location '{item_name}' in 'locations'.")
                added_count += 1
            except Exception as e:
                print(f"Error adding/updating location '{item_name}' to 'locations': {e}")
        else:
            print(f"Skipping location '{item_name}' due to embedding generation failure.")

        # Optional: Add a small delay to avoid hitting API rate limits
        time.sleep(0.5)

    print(f"Successfully added/updated {added_count} out of {len(locations_data_list)} items in 'locations'.")

def insert_activities_data(activities_data_list):
    """Inserts activity data with generated embeddings into the 'activities' table."""
    added_count = 0
    total_activities_to_process = sum(len(sight_item.get("activities", [])) for sight_item in activities_data_list)
    current_activity_index = 0

    print(f"\n--- Adding data to 'activities' table ---")
    for sight_item in activities_data_list:
        sight_id = sight_item.get('sight_id')
        if not sight_id:
            print(f"Warning: Skipping sight item due to missing 'sight_id': {sight_item}")
            continue

        for activity in sight_item.get("activities", []):
            current_activity_index += 1
            activity_name = activity.get('name')
            activity_description = activity.get('description')

            if not activity_name or not activity_description:
                print(f"Warning: Skipping activity due to missing name or description in sight '{sight_id}': {activity}")
                continue

            print(f"[{current_activity_index}/{total_activities_to_process}] Generating embedding for activity '{activity_name}' (Sight: {sight_id})...")
            embedding_values = generate_embedding(f"activity_description: {activity_description}, activity_name: {activity_name}")

            if embedding_values:
                try:
                    if len(embedding_values) != EMBEDDING_DIMENSION:
                        print(f"Warning: Embedding for activity '{activity_name}' has dimension {len(embedding_values)}, expected {EMBEDDING_DIMENSION}. Skipping.")
                        continue

                    cur.execute("""
                        INSERT INTO activities (activity_id, name, duration_min, duration_max, kid_friendliness_score, cost, sight_id, description, embedding)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                        ON CONFLICT (activity_id) DO UPDATE SET
                            name = EXCLUDED.name,
                            duration_min = EXCLUDED.duration_min,
                            duration_max = EXCLUDED.duration_max,
                            kid_friendliness_score = EXCLUDED.kid_friendliness_score,
                            cost = EXCLUDED.cost,
                            sight_id = EXCLUDED.sight_id,
                            description = EXCLUDED.description,
                            embedding = EXCLUDED.embedding;
                    """, (
                        activity['activity_id'], activity_name,
                        activity.get('duration_range_mins', [None, None])[0], # Default to None if missing
                        activity.get('duration_range_mins', [None, None])[1] if len(activity.get('duration_range_mins', [])) > 1 else None, # Default to None
                        activity.get('kid_friendliness_score'), activity.get('cost_gbp'),
                        sight_id, activity_description, embedding_values
                    ))
                    conn.commit()
                    print(f"Added/Updated activity '{activity_name}' in 'activities'.")
                    added_count += 1
                except Exception as e:
                    print(f"Error adding/updating activity '{activity_name}' to 'activities': {e}")
            else:
                print(f"Skipping activity '{activity_name}' due to embedding generation failure.")
            time.sleep(0.5) # API rate limiting

    print(f"Successfully added/updated {added_count} out of {total_activities_to_process} activities in 'activities'.")


if __name__ == "__main__":
    if conn:
        # Determine the base directory of the script
       

        # --- Load Locations Data (from london_attractions.json) ---
        locations_file_path = os.path.join(parent_dir, 'london_attractions.json')
        try:
            with open(locations_file_path, 'r') as f:
                locations_data = json.load(f)
            print(f"Successfully loaded locations data from {locations_file_path}")
        except FileNotFoundError:
            print(f"Error: Locations file not found at {locations_file_path}")
            locations_data = []
        except json.JSONDecodeError:
            print(f"Error: Could not decode JSON from {locations_file_path}")
            locations_data = []

        # --- Load Activities Data (from london_activities.json) ---
        activities_file_path = os.path.join(parent_dir, 'london_activities.json')
        try:
            with open(activities_file_path, 'r') as f:
                activities_data = json.load(f)
            print(f"Successfully loaded activities data from {activities_file_path}")
        except FileNotFoundError:
            print(f"Error: Activities file not found at {activities_file_path}")
            activities_data = []
        except json.JSONDecodeError:
            print(f"Error: Could not decode JSON from {activities_file_path}")
            activities_data = []

        # --- Process Locations ---
        # if locations_data:
        #     insert_locations_data(locations_data)

        # --- Process Activities ---
        if activities_data:
            insert_activities_data(activities_data)

        # Close the connection
        cur.close()
        conn.close()
        print("\nPostgreSQL connection closed.")
